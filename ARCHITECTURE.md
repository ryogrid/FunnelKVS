# Rustの手習い用に開発する分散KVS の設計メモ

- RedisやMemcachedのようなオンメモリでデータを保持するデータストアを実現する
- データの他ノードによる中継などによってNAT越え（要は複数の異なるネットワークにノードが存在する場合）することまで考えると、実装がかなり複雑になることが予想されるため、今回は単一ネットワーク内に全ノードがいて、それらのノード間で直接通信が可能であることを前提とする
- 各ノードは構成されたKVSへアクセスするための put, get, delete をREST API として提供する
  - 今回はパフォーマンスに重きを置かないこともあり、ストアできるデータはJSON形式として解釈可能なものに限定する（Valueの部分）
  - Keyの部分はそれほど大きくなることを想定せず、API呼び出し時のURLの部分に含める
  - KVSへのアクセスとは別に、DHTを構成するための通信も、（ひとまずは）REST APIとして定義し、ノード間のやり取りはそれを用いて行うものとする（いちいちソケットプログラミングするのは面倒なので・・）。コネクションを継続的に張り続けておかないと実装が複雑化するといったことが判明した場合は、見直しを行う
- 分散ハッシュテーブル（Distributed Hash Table, DHT）の技術を用いて、中央サーバ無しで動作するものとする
  - DHTのアルゴリズム（プロトコル）としては一番ポピュラーな "Chord" をを採用する
  - 参考にする資料・ウェブサイト
    - [分散システムにおけるScalableな名前付けアルゴリズム「Chord Protocol」を実装してみた - Qiita](https://qiita.com/taisho6339/items/7f849b65e2deab6759a1)
    - [ChordアルゴリズムによるDHT入門 - slideshare](https://www.slideshare.net/did2/chorddht)
    - [VIOPS04: DHTの基礎知識- slideshare](https://www.slideshare.net/viopsjp/dht20091211)
  - Chordネットワークの利用方法
    - Chordネットワーク
      - ChordネットワークはあくまでデータのIDから「担当ノード」のアドレスを得るための一種の名前解決の仕組みとして利用する
      - put, get, delete のいずれも、「担当ノード」とそのアドレスが判明してから、直接該当する操作を行う形とする
      - 広域分散のネットワークを構築する場合は、ルーティングや経路表の作成にあたって、NAT内に存在するノードへ対応するための考慮を加えなければならないと思われるが、それに加えて、UPnPを用いて、各ノードのデーモンがNATに穴を空けてグローバルIPでアクセス可能となるように振舞うことで、ネットワーク全体でグローバルIPでアクセス可能なノードの割合を増やさないと成立しないであろうと思われる
  - 実装にあたって
    - VIOSP04のスライドのP9に記述されている疑似コードであるが、ノード空間が6ビットより大きかったら再帰、もしくはループを用いた呼び出しがどこかに必要となると思われる
    - 一例としては、一番上の n.find_successor という関数を、n' を更新しながら回るwhileループにて、n'.find_predecessor が対象とするIDをsuccessorList内に含むpredecessor（n'）まで到達して、そのn'から探している「担当ノード」の情報（とその後ろに位置する、successorListに含まれるノードの情報）を返してもらえるまで続ける
      - 「担当ノード」の後ろに位置するノードの情報も受け取るのは、「担当ノード」がsuccessorノードに対してデータをレプリケーションしていれば、「担当ノード」が離脱していたり、他のノードの参加により、担当範囲が変更となり、データを保持していなかったとしても、レプリケーションしていたノードからデータを得られるため
    - n'.find_predecessorがpredecessorではなく「担当ノード」（+α）を返す場合は、疑似コードで言えば判別可能なフラグを返り値に加えるなどすればよいはず
    - 上述のような変更を加えるのであれば関数名は適切なものに変更することが望ましいであろう
    - ネットワークのstabilizeが局所的に完了していない状態で、かつ、運悪く所望のデータを保持するノードが発見できなかった場合はエラーを返せば・・・よいか
      - データのIDを担当するはずのノード、もしくはその後続のノード群全てがデータを保持していない場合
      - 通信回りでのトラブルを考慮しない場合に、ネットワークの規模や、下層の実ネットワークの速度、各ノード処理時間を考慮した上で、探索に要する最悪時間が大体求まり、その時間以内にデータを得られないことが必ず判明するのかは現状不明（そうでない場合、つまり、探索処理におけるノード遷移が滅茶苦茶になり、いつになっても終了しないというケースが存在する場合、タイムアウトの処理も加える必要がある）
- ストアしたデータはオンメモリだけで保持し、ストレージへの永続化はひとまず考えない
- ストレージへの永続化はしないが、DHTのアドレス空間上での隣接ノード等を相手方としたデータのレプリケーションは実装する。これにより、全ノードないし
多数のノードを一斉に落とすといったことをしなければ、データは失われないようになる（はず）
- 実装にはRust言語を用い、REST API実装のフレームワークや、極めて一般的な処理を担うライブラリを除き、フルスクラッチで実装する
- Chordアルゴリズムの理解とそれに基づく設計の検証のため、簡易的な、Chordネットワークのシミュレータを Python（今のところの第一候補）を用いて作成する予定
  - 実システムを今回初めてまともに利用するRust言語で書いている中で、Chordの実装方法の誤りによる想定しない動作が発生した場合、デバッグのコストが非常に大きくなることが予想されるため
